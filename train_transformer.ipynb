{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 0, '1': 1, '10': 2, '100': 3, '1000': 4, '10000': 5, '11': 6, '112': 7, '119': 8, '12': 9, '13': 10, '14': 11, '15': 12, '16': 13, '17': 14, '18': 15, '19': 16, '2': 17, '20': 18, '21': 19, '22': 20, '23': 21, '24': 22, '25': 23, '26': 24, '27': 25, '28': 26, '29': 27, '3': 28, '30': 29, '31': 30, '32': 31, '33': 32, '34': 33, '35': 34, '36': 35, '37': 36, '38': 37, '39': 38, '4': 39, '40': 40, '41': 41, '42': 42, '43': 43, '44': 44, '45': 45, '46': 46, '47': 47, '48': 48, '49': 49, '5': 50, '50': 51, '51': 52, '52': 53, '53': 54, '54': 55, '55': 56, '56': 57, '57': 58, '58': 59, '59': 60, '6': 61, '60': 62, '61': 63, '62': 64, '63': 65, '64': 66, '65': 67, '66': 68, '67': 69, '68': 70, '69': 71, '7': 72, '70': 73, '71': 74, '72': 75, '73': 76, '74': 77, '75': 78, '76': 79, '77': 80, '78': 81, '79': 82, '8': 83, '80': 84, '81': 85, '82': 86, '83': 87, '84': 88, '85': 89, '86': 90, '87': 91, '88': 92, '89': 93, '9': 94, '90': 95, '91': 96, '92': 97, '93': 98, '94': 99, '95': 100, '96': 101, '97': 102, '98': 103, '99': 104, '가렵다': 105, '가스': 106, '가슴': 107, '가시': 108, '각목': 109, '갇히다': 110, '감금': 111, '감전': 112, '강': 113, '강남구': 114, '강동구': 115, '강북구': 116, '강서구': 117, '강풍': 118, '개': 119, '거실': 120, '걸렸다': 121, '결박': 122, '경운기': 123, '경찰': 124, '경찰차': 125, '계곡': 126, '계단': 127, '고속도로': 128, '고압전선': 129, '고열': 130, '고장': 131, '골절': 132, '곰': 133, '공사장': 134, '공원': 135, '공장': 136, '관악구': 137, '광진구': 138, '교통사고': 139, '구급대': 140, '구급대원': 141, '구급차': 142, '구로구': 143, '구청': 144, '구해주세요': 145, '귀': 146, '금가다': 147, '금요일': 148, '금천구': 149, '급류': 150, '기절': 151, '기절하다': 152, '깔리다': 153, '끓는물': 154, '남자친구': 155, '남편': 156, '남학생': 157, '납치': 158, '낫': 159, '낯선남자': 160, '낯선사람': 161, '낯선여자': 162, '내년': 163, '내일': 164, '냄새나다': 165, '노원구': 166, '논': 167, '놀이터': 168, '농약': 169, '누나': 170, '누수': 171, '누전': 172, '누출': 173, '눈': 174, '다리': 175, '다음': 176, '달(월)': 177, '대문앞': 178, '도둑': 179, '도로': 180, '도봉구': 181, '독극물': 182, '독버섯': 183, '독사': 184, '동대문구': 185, '동생': 186, '동작구': 187, '동전': 188, '두드러기생기다': 189, '뒤': 190, '뒤통수': 191, '등': 192, '딸': 193, '떨어지다': 194, '뜨거운물': 195, '마당': 196, '마포구': 197, '말려주세요': 198, '말벌': 199, '맹견': 200, '머리': 201, '멧돼지': 202, '목': 203, '목요일': 204, '무너지다': 205, '무릎': 206, '문틈': 207, '물': 208, '밑에': 209, '바다': 210, '반점생기다': 211, '발': 212, '발가락': 213, '발목': 214, '발작': 215, '방망이': 216, '밭': 217, '배': 218, '배고프다': 219, '뱀': 220, '벌': 221, '범람': 222, '벼락': 223, '병원': 224, '보건소': 225, '보내주세요(경찰)': 226, '보내주세요(구급차)': 227, '복부': 228, '복통': 229, '볼': 230, '부러지다': 231, '부엌': 232, '불': 233, '불나다': 234, '붕괴': 235, '붕대': 236, '비닐하우스': 237, '비상약': 238, '빌라': 239, '뼈': 240, '사이': 241, '산': 242, '살충제': 243, '살해': 244, '삼키다': 245, '서대문구': 246, '서랍': 247, '서울시': 248, '서초구': 249, '선반': 250, '선생님': 251, '성동구': 252, '성북구': 253, '성폭행': 254, '소방관': 255, '소방차': 256, '소화기': 257, '소화전': 258, '손': 259, '손가락': 260, '손목': 261, '송파구': 262, '수영장': 263, '수요일': 264, '술취한 사람': 265, '숨을안쉬다': 266, '시청': 267, '신고하세요(경찰)': 268, '심장마비': 269, '쓰러지다': 270, '아기': 271, '아내': 272, '아들': 273, '아래': 274, '아빠': 275, '아이들': 276, '아저씨': 277, '아줌마': 278, '아파트': 279, '안방': 280, '알려주세요': 281, '앞': 282, '앞집': 283, '약국': 284, '약사': 285, '양천구': 286, '어깨': 287, '어린이': 288, '어제': 289, '어지러움': 290, '언니': 291, '얼굴': 292, '엄마': 293, '엘리베이터': 294, '여자친구': 295, '여학생': 296, '연기': 297, '연락해주세요': 298, '열': 299, '열나다': 300, '열어주세요': 301, '엽총': 302, '영등포구': 303, '옆집': 304, '옆집 아저씨': 305, '옆집 할아버지': 306, '옆집사람': 307, '옆쪽': 308, '오늘': 309, '오른쪽': 310, '오른쪽-귀': 311, '오른쪽-눈': 312, '오빠': 313, '옥상': 314, '올해': 315, '왼쪽': 316, '왼쪽-귀': 317, '왼쪽-눈': 318, '욕실': 319, '용산구': 320, '우리집': 321, '운동장': 322, '월요일': 323, '위': 324, '위에': 325, '위협': 326, '윗집': 327, '윗집사람': 328, '유리': 329, '유치원': 330, '유치원 버스': 331, '은평구': 332, '음식물': 333, '응급대원': 334, '응급처리': 335, '의사': 336, '이마': 337, '이물질': 338, '이번': 339, '이상한사람': 340, '이웃집': 341, '인대': 342, '일요일': 343, '임산부': 344, '임신한아내': 345, '자동차': 346, '자살': 347, '자상': 348, '작년': 349, '작은방': 350, '장난감': 351, '장단지': 352, '절단': 353, '절도': 354, '제초제': 355, '조난': 356, '종로구': 357, '주': 358, '중구': 359, '중랑구': 360, '지난': 361, '지혈대': 362, '진통제': 363, '질식': 364, '집': 365, '집단폭행': 366, '차밖': 367, '차안': 368, '창문': 369, '창백하다': 370, '체온계': 371, '총': 372, '추락': 373, '축사': 374, '출산': 375, '출혈': 376, '친구': 377, '침수': 378, '칼': 379, '코': 380, '탈골': 381, '택시': 382, '토요일': 383, '토하다': 384, '통학버스': 385, '트랙터': 386, '트럭': 387, '파도': 388, '파편': 389, '팔': 390, '팔꿈치': 391, '폭발': 392, '폭우': 393, '폭탄': 394, '폭행': 395, '피나다': 396, '학교': 397, '학생': 398, '할머니': 399, '할아버지': 400, '함몰되다': 401, '해(연)': 402, '해독제': 403, '해열제': 404, '허리': 405, '허벅지': 406, '현관': 407, '현관앞': 408, '협박': 409, '형': 410, '호흡곤란': 411, '호흡기': 412, '홍수': 413, '화상': 414, '화약': 415, '화요일': 416, '화장실': 417, '화재': 418}\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드드\n",
    "data = np.load('data/seq1~3000_60fps_1741667844.npy')\n",
    "data.shape\n",
    "\n",
    "### label - idx mapping정보 가져오기\n",
    "import pickle\n",
    "with open('data/label_to_idx.pickle', 'rb') as f:\n",
    "    label_to_idx = pickle.load(f)\n",
    "print(label_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159020, 60, 198)\n",
      "(159020,)\n"
     ]
    }
   ],
   "source": [
    "# 라벨 값 분리\n",
    "x_data = data[:,:,:-1]\n",
    "labels = data[:, 0, -1]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143118, 60, 198) (143118,)\n",
      "(15902, 60, 198) (15902,)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 6800967360 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_train\u001b[38;5;241m.\u001b[39mshape, y_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_val\u001b[38;5;241m.\u001b[39mshape, y_val\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 11\u001b[0m x_train \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m y_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_train, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m     13\u001b[0m x_val \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(x_val, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 6800967360 bytes."
     ]
    }
   ],
   "source": [
    "# train test data split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = labels.astype(np.float32)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size = 0.1, random_state=42)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네트워크 변수 설정\n",
    "\n",
    "batch_size = 64\n",
    "seq_len = 60\n",
    "num_angles = 198\n",
    "num_classes = len(label_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class NumpyToTensorDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x  # numpy 배열\n",
    "        self.y = y  # numpy 배열\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_item = torch.tensor(self.x[idx], dtype=torch.float32)  # numpy → tensor 변환\n",
    "        y_item = torch.tensor(self.y[idx], dtype=torch.long)  # numpy → tensor 변환\n",
    "        return x_item, y_item\n",
    "\n",
    "train_dataset = NumpyToTensorDataset(x_train, y_train)\n",
    "test_dataset = NumpyToTensorDataset(x_val, y_val)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HyeonjiKim\\anaconda3\\envs\\p-project\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_angles, num_classes, d_model=128, num_heads=4, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Linear(num_angles, d_model)# 각 프레임의 앵글 값을 d_model 차원으로 변환\n",
    "        self.pos_encoder = nn.Parameter(torch.zeros(1,seq_len, d_model)) # 위치 인코딩\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads, dropout=dropout) \n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc = nn.Linear(d_model, num_classes) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) + self.pos_encoder # B, T, d_model\n",
    "        x = self.transformer_encoder(x) # B,T, d_model\n",
    "        x = x.mean(dim=1) # 전체 시퀀스에 대한 평균 (B, d_model)\n",
    "        return self.fc(x)  # (B, num_classes)\n",
    "    \n",
    "model = Transformer(num_angles=num_angles, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HyeonjiKim\\AppData\\Local\\Temp\\ipykernel_8552\\276412949.py:15: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  y_item = torch.tensor(self.y[idx], dtype=torch.long)  # numpy → tensor 변환\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "step() missing 1 required positional argument: 'metrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m         test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m criterion(outputs, y)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     37\u001b[0m         acc\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39mcorrect\u001b[38;5;241m/\u001b[39mtotal)\n\u001b[1;32m---> 39\u001b[0m \u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, LR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscheduler\u001b[38;5;241m.\u001b[39mget_last_lr()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m [Test] : Average loss : \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m, Accuracy : \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{:.0f}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     44\u001b[0m                   \u001b[38;5;241m.\u001b[39mformat(test_loss,correct,total,\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39m correct\u001b[38;5;241m/\u001b[39mtotal))\n",
      "\u001b[1;31mTypeError\u001b[0m: step() missing 1 required positional argument: 'metrics'"
     ]
    }
   ],
   "source": [
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "# 간단한 학습 과정\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for x, y in train_dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        test_loss = 0\n",
    "        acc = []\n",
    "        for x, y in test_dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            outputs = model(x)\n",
    "            _,predicted = torch.max(outputs.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            test_loss += criterion(outputs, y).item()\n",
    "            acc.append(100*correct/total)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}, LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "    print('\\t [Test] : Average loss : {:.4f}, Accuracy : {}/{}({:.0f}%)\\n'\n",
    "                      .format(test_loss,correct,total,100* correct/total))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
