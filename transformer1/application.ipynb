{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input : mediapipe 손 keypoint (21,4)\n",
    "# out : angle (15,)\n",
    "def cal_angle(joint):\n",
    "    # 벡터 계산\n",
    "    v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19], :3] # Parent joint\n",
    "    v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], :3] # Child joint\n",
    "    v = v2 - v1 # [20, 3]\n",
    "\n",
    "    # normalize v : 길이로 나누기\n",
    "    v = v/np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "\n",
    "    # arccos dot product로 앵글 구하기\n",
    "    angle = np.arccos(np.einsum('nt, nt->n',\n",
    "                                v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18], :],\n",
    "                                v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])) # [15,]\n",
    "\n",
    "    # radian을 degree(도)로 변경\n",
    "    angle = np.degrees(angle) \n",
    "\n",
    "    angle = np.array([angle], dtype=np.float32)\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_keypoints(results):\n",
    "\n",
    "    # 왼손 키포인트 추출\n",
    "    if results.left_hand_landmarks:\n",
    "        joint_left = np.zeros((21,4))\n",
    "        # 키포인트 추출\n",
    "        for j, lm in enumerate(results.left_hand_landmarks.landmark):\n",
    "            joint_left[j] = [lm.x, lm.y, lm.z, lm.visibility]\n",
    "        # 앵글 계산 [15,]\n",
    "        angle_left = cal_angle(joint_left)\n",
    "    else:\n",
    "        joint_left = np.zeros((21,4))\n",
    "        angle_left = [np.zeros((15,))]\n",
    "\n",
    "    # 오른손 키포인트 추출\n",
    "    if results.right_hand_landmarks:\n",
    "        joint_right = np.zeros((21,4))\n",
    "        # 키포인트 추출\n",
    "        for j, lm in enumerate(results.right_hand_landmarks.landmark):\n",
    "            joint_right[j] = [lm.x, lm.y, lm.z, lm.visibility]\n",
    "        # 앵글 계산\n",
    "        angle_right = cal_angle(joint_right)\n",
    "    else:\n",
    "        joint_right = np.zeros((21,4))\n",
    "        angle_right = [np.zeros((15,))]\n",
    "    \n",
    "\n",
    "    frame_angle = np.concatenate([angle_left, angle_right])\n",
    "\n",
    "    d = np.concatenate([joint_left.flatten(), joint_right.flatten(), frame_angle.flatten()])\n",
    "\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화 from train_transformer.ipynb\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_angles, num_classes, seq_len=60, d_model=128, num_heads=4, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Linear(num_angles, d_model)# 각 프레임의 앵글 값을 d_model 차원으로 변환\n",
    "        self.pos_encoder = nn.Parameter(torch.zeros(1, seq_len, d_model)) # 위치 인코딩\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads, dropout=dropout) \n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc = nn.Linear(d_model, num_classes) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) + self.pos_encoder # B, T, d_model\n",
    "        x = self.transformer_encoder(x) # B,T, d_model\n",
    "        x = x.mean(dim=1) # 전체 시퀀스에 대한 평균 (B, d_model)\n",
    "        return self.fc(x)  # (B, num_classes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 0, '1': 1, '10': 2, '100': 3, '1000': 4, '10000': 5, '11': 6, '112': 7, '119': 8, '12': 9, '13': 10, '14': 11, '15': 12, '16': 13, '17': 14, '18': 15, '19': 16, '2': 17, '20': 18, '21': 19, '22': 20, '23': 21, '24': 22, '25': 23, '26': 24, '27': 25, '28': 26, '29': 27, '3': 28, '30': 29, '31': 30, '32': 31, '33': 32, '34': 33, '35': 34, '36': 35, '37': 36, '38': 37, '39': 38, '4': 39, '40': 40, '41': 41, '42': 42, '43': 43, '44': 44, '45': 45, '46': 46, '47': 47, '48': 48, '49': 49, '5': 50, '50': 51, '51': 52, '52': 53, '53': 54, '54': 55, '55': 56, '56': 57, '57': 58, '58': 59, '59': 60, '6': 61, '60': 62, '61': 63, '62': 64, '63': 65, '64': 66, '65': 67, '66': 68, '67': 69, '68': 70, '69': 71, '7': 72, '70': 73, '71': 74, '72': 75, '73': 76, '74': 77, '75': 78, '76': 79, '77': 80, '78': 81, '79': 82, '8': 83, '80': 84, '81': 85, '82': 86, '83': 87, '84': 88, '85': 89, '86': 90, '87': 91, '88': 92, '89': 93, '9': 94, '90': 95, '91': 96, '92': 97, '93': 98, '94': 99, '95': 100, '96': 101, '97': 102, '98': 103, '99': 104, '가렵다': 105, '가스': 106, '가슴': 107, '가시': 108, '각목': 109, '갇히다': 110, '감금': 111, '감전': 112, '강': 113, '강남구': 114, '강동구': 115, '강북구': 116, '강서구': 117, '강풍': 118, '개': 119, '거실': 120, '걸렸다': 121, '결박': 122, '경운기': 123, '경찰': 124, '경찰차': 125, '계곡': 126, '계단': 127, '고속도로': 128, '고압전선': 129, '고열': 130, '고장': 131, '골절': 132, '곰': 133, '공사장': 134, '공원': 135, '공장': 136, '관악구': 137, '광진구': 138, '교통사고': 139, '구급대': 140, '구급대원': 141, '구급차': 142, '구로구': 143, '구청': 144, '구해주세요': 145, '귀': 146, '금가다': 147, '금요일': 148, '금천구': 149, '급류': 150, '기절': 151, '기절하다': 152, '깔리다': 153, '끓는물': 154, '남자친구': 155, '남편': 156, '남학생': 157, '납치': 158, '낫': 159, '낯선남자': 160, '낯선사람': 161, '낯선여자': 162, '내년': 163, '내일': 164, '냄새나다': 165, '노원구': 166, '논': 167, '놀이터': 168, '농약': 169, '누나': 170, '누수': 171, '누전': 172, '누출': 173, '눈': 174, '다리': 175, '다음': 176, '달(월)': 177, '대문앞': 178, '도둑': 179, '도로': 180, '도봉구': 181, '독극물': 182, '독버섯': 183, '독사': 184, '동대문구': 185, '동생': 186, '동작구': 187, '동전': 188, '두드러기생기다': 189, '뒤': 190, '뒤통수': 191, '등': 192, '딸': 193, '떨어지다': 194, '뜨거운물': 195, '마당': 196, '마포구': 197, '말려주세요': 198, '말벌': 199, '맹견': 200, '머리': 201, '멧돼지': 202, '목': 203, '목요일': 204, '무너지다': 205, '무릎': 206, '문틈': 207, '물': 208, '밑에': 209, '바다': 210, '반점생기다': 211, '발': 212, '발가락': 213, '발목': 214, '발작': 215, '방망이': 216, '밭': 217, '배': 218, '배고프다': 219, '뱀': 220, '벌': 221, '범람': 222, '벼락': 223, '병원': 224, '보건소': 225, '보내주세요(경찰)': 226, '보내주세요(구급차)': 227, '복부': 228, '복통': 229, '볼': 230, '부러지다': 231, '부엌': 232, '불': 233, '불나다': 234, '붕괴': 235, '붕대': 236, '비닐하우스': 237, '비상약': 238, '빌라': 239, '뼈': 240, '사이': 241, '산': 242, '살충제': 243, '살해': 244, '삼키다': 245, '서대문구': 246, '서랍': 247, '서울시': 248, '서초구': 249, '선반': 250, '선생님': 251, '성동구': 252, '성북구': 253, '성폭행': 254, '소방관': 255, '소방차': 256, '소화기': 257, '소화전': 258, '손': 259, '손가락': 260, '손목': 261, '송파구': 262, '수영장': 263, '수요일': 264, '술취한 사람': 265, '숨을안쉬다': 266, '시청': 267, '신고하세요(경찰)': 268, '심장마비': 269, '쓰러지다': 270, '아기': 271, '아내': 272, '아들': 273, '아래': 274, '아빠': 275, '아이들': 276, '아저씨': 277, '아줌마': 278, '아파트': 279, '안방': 280, '알려주세요': 281, '앞': 282, '앞집': 283, '약국': 284, '약사': 285, '양천구': 286, '어깨': 287, '어린이': 288, '어제': 289, '어지러움': 290, '언니': 291, '얼굴': 292, '엄마': 293, '엘리베이터': 294, '여자친구': 295, '여학생': 296, '연기': 297, '연락해주세요': 298, '열': 299, '열나다': 300, '열어주세요': 301, '엽총': 302, '영등포구': 303, '옆집': 304, '옆집 아저씨': 305, '옆집 할아버지': 306, '옆집사람': 307, '옆쪽': 308, '오늘': 309, '오른쪽': 310, '오른쪽-귀': 311, '오른쪽-눈': 312, '오빠': 313, '옥상': 314, '올해': 315, '왼쪽': 316, '왼쪽-귀': 317, '왼쪽-눈': 318, '욕실': 319, '용산구': 320, '우리집': 321, '운동장': 322, '월요일': 323, '위': 324, '위에': 325, '위협': 326, '윗집': 327, '윗집사람': 328, '유리': 329, '유치원': 330, '유치원 버스': 331, '은평구': 332, '음식물': 333, '응급대원': 334, '응급처리': 335, '의사': 336, '이마': 337, '이물질': 338, '이번': 339, '이상한사람': 340, '이웃집': 341, '인대': 342, '일요일': 343, '임산부': 344, '임신한아내': 345, '자동차': 346, '자살': 347, '자상': 348, '작년': 349, '작은방': 350, '장난감': 351, '장단지': 352, '절단': 353, '절도': 354, '제초제': 355, '조난': 356, '종로구': 357, '주': 358, '중구': 359, '중랑구': 360, '지난': 361, '지혈대': 362, '진통제': 363, '질식': 364, '집': 365, '집단폭행': 366, '차밖': 367, '차안': 368, '창문': 369, '창백하다': 370, '체온계': 371, '총': 372, '추락': 373, '축사': 374, '출산': 375, '출혈': 376, '친구': 377, '침수': 378, '칼': 379, '코': 380, '탈골': 381, '택시': 382, '토요일': 383, '토하다': 384, '통학버스': 385, '트랙터': 386, '트럭': 387, '파도': 388, '파편': 389, '팔': 390, '팔꿈치': 391, '폭발': 392, '폭우': 393, '폭탄': 394, '폭행': 395, '피나다': 396, '학교': 397, '학생': 398, '할머니': 399, '할아버지': 400, '함몰되다': 401, '해(연)': 402, '해독제': 403, '해열제': 404, '허리': 405, '허벅지': 406, '현관': 407, '현관앞': 408, '협박': 409, '형': 410, '호흡곤란': 411, '호흡기': 412, '홍수': 413, '화상': 414, '화약': 415, '화요일': 416, '화장실': 417, '화재': 418}\n"
     ]
    }
   ],
   "source": [
    "### label - idx mapping정보 가져오기\n",
    "import pickle\n",
    "with open('../data/label_to_idx.pickle', 'rb') as f:\n",
    "    label_to_idx = pickle.load(f)\n",
    "print(label_to_idx)\n",
    "idx_to_label = {value : key for key, value in label_to_idx.items()} ## idx로 label접근\n",
    "\n",
    "\n",
    "num_angles = 198\n",
    "num_classes = len(label_to_idx)\n",
    "frame = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742795460.282089 5948793 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M2 Max\n",
      "W0000 00:00:1742795460.355451 5952195 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742795460.366601 5952195 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742795460.368907 5952192 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742795460.368950 5952198 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742795460.369132 5952200 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742795460.372990 5952200 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742795460.375470 5952201 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742795460.375533 5952198 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m success, image \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     29\u001b[0m imageRGB \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m---> 30\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mholistic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimageRGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# print(\"왼손 랜드마크: \", results.left_hand_landmarks)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# print(\"오른손 랜드마크: \", results.right_hand_landmarks)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# print(\"얼굴 랜드마크: \", results.face_landmarks)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# print(\"pose 랜드마크: \", results.pose_landmarks)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m keypoints \u001b[38;5;241m=\u001b[39m extract_keypoints(results)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mediapipe/python/solutions/holistic.py:160\u001b[0m, in \u001b[0;36mHolistic.process\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[1;32m    137\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the pose landmarks, left and right hand landmarks, and face landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mediapipe/python/solution_base.py:340\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    334\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[1;32m    336\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[1;32m    337\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[1;32m    338\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[0;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "# 비디오\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 웹캠 프레임 크기를 정사각형으로 설정\n",
    "frame_size = 640\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, frame_size)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_size)\n",
    "\n",
    "# holistic설정\n",
    "mp_holistic = mp.solutions.holistic\n",
    "holistic = mp_holistic.Holistic()\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "mp_draw_styles = mp.solutions.drawing_styles\n",
    "\n",
    "### 모델 가져오기 ###\n",
    "graph_args = {\"layout\": \"mediapipe\", \"strategy\": \"spatial\"}\n",
    "loaded_model = Transformer(num_angles=num_angles, num_classes=num_classes)\n",
    "loaded_model.load_state_dict(torch.load(\"../model/transformer_60fps.pth\", map_location=torch.device('cpu')))\n",
    "\n",
    "keypoint_sequence = []\n",
    "\n",
    "\n",
    "sentence = [\" \", ]\n",
    "\n",
    "# 이미지 입력 캡처 및 처리\n",
    "# media pipe 는 RGB\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = holistic.process(imageRGB)\n",
    "\n",
    "    # print(\"왼손 랜드마크: \", results.left_hand_landmarks)\n",
    "    # print(\"오른손 랜드마크: \", results.right_hand_landmarks)\n",
    "    # print(\"얼굴 랜드마크: \", results.face_landmarks)\n",
    "    # print(\"pose 랜드마크: \", results.pose_landmarks)\n",
    "\n",
    "    keypoints = extract_keypoints(results)\n",
    "    keypoint_sequence.append(keypoints)\n",
    "    sequence = keypoint_sequence[-frame:]  # 마지막  frame으로 prediction 한다\n",
    "\n",
    "\n",
    "    if len(sequence) == frame:  # 60 프레임\n",
    "\n",
    "        output = loaded_model(torch.tensor(sequence, dtype=torch.float32))\n",
    "        prediction = torch.argmax(output, dim=1)\n",
    "        prediction_value = prediction.item()\n",
    "\n",
    "        if output[0, prediction_value]>30:\n",
    "            if idx_to_label[prediction_value] != sentence[-1]:\n",
    "                sentence.append(idx_to_label[prediction_value])\n",
    "\n",
    "                print('prediction ', prediction_value, ':', idx_to_label[prediction_value])\n",
    "                print('acc ', output[0, prediction_value]) # (batch, class)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 점 그리기\n",
    "    annotated_image = image.copy()\n",
    "    mp_draw.draw_landmarks(annotated_image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_draw.draw_landmarks(annotated_image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "\n",
    "    cv2.imshow('output', annotated_image)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "\n",
    "\n",
    "cap.release()\n",
    "holistic.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
